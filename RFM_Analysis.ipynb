{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3vR+ndR0vkD6lx5U43Jr2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syankov-ai/Medium/blob/main/RFM_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker -q"
      ],
      "metadata": {
        "id": "8f0JSkx9UEyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw Data"
      ],
      "metadata": {
        "id": "qVMef_jfUV8X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFAMCjC6T_Lj"
      },
      "outputs": [],
      "source": [
        "from faker import Faker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Specify the number of dataset rows and customers\n",
        "num_rows = 1000\n",
        "num_customers = 300\n",
        "\n",
        "# Simulate repeat customers\n",
        "customer_ids = np.random.choice(np.arange(100, 10000), num_customers, replace=False)\n",
        "repeat_ids = np.random.choice(customer_ids, num_rows)\n",
        "\n",
        "# Random purchase dates over past 2 years\n",
        "purchase_dates = [fake.date_between(start_date='-2y', end_date='today') for _ in range(num_rows)]\n",
        "\n",
        "# Amounts between 10 and 1000\n",
        "transaction_amounts = np.round(np.random.uniform(10, 1000, num_rows), 2)\n",
        "\n",
        "# 4 possible products\n",
        "product_info = np.random.choice(['Tasty Bites', 'T-Shirt Mouse', 'Penguin Snack', 'Handy Thing'], num_rows)\n",
        "\n",
        "# 6-digit unique order ids\n",
        "order_ids = np.random.randint(100000, 999999, num_rows)\n",
        "\n",
        "# Use Faker for locations\n",
        "locations = [fake.city() for _ in range(num_rows)]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'customer_id': repeat_ids,\n",
        "    'purchase_date': purchase_dates,\n",
        "    'transaction_amount': transaction_amounts,\n",
        "    'product_information': product_info,\n",
        "    'order_id': order_ids,\n",
        "    'location': locations\n",
        "})\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recency"
      ],
      "metadata": {
        "id": "uG1Eih9mWZYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ensure date column is interpreted as datetime\n",
        "df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
        "\n",
        "# Compute each customer's most recent purchase\n",
        "df_recency = df.groupby(by='customer_id', as_index=False)['purchase_date'].max()\n",
        "df_recency.columns = ['customer_id', 'last_purchase_date']\n",
        "\n",
        "# Find most recent date in dataset for recency calculation\n",
        "recent_date = df_recency['last_purchase_date'].max()\n",
        "\n",
        "# Calculate recency in days (how long since last purchase)\n",
        "df_recency['recency'] = df_recency['last_purchase_date'].apply(lambda x: (recent_date - x).days)\n",
        "\n",
        "# Visualize distribution of recency using seaborn\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_recency['recency'], bins=30, kde=True, color=\"skyblue\")\n",
        "plt.title('Distribution of Customer Recency')\n",
        "plt.xlabel('Recency (days since last purchase)')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-veGDqDBWZPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frequency"
      ],
      "metadata": {
        "id": "-rvGY605ZWZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicate purchase records to count only unique transactions\n",
        "frequency_df = df.drop_duplicates().groupby(by=['customer_id'], as_index=False)['purchase_date'].count()\n",
        "\n",
        "# Rename columns for clarity\n",
        "frequency_df.columns = ['customer_id', 'frequency']\n",
        "\n",
        "# Display first few rows\n",
        "frequency_df.head()\n",
        "\n",
        "# Visualization: Distribution of purchase frequency\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(frequency_df['frequency'], bins=9, kde=False, color=\"salmon\")\n",
        "plt.title('Distribution of Purchase Frequency Among Customers')\n",
        "plt.xlabel('Number of Unique Purchases')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0D8Fh5TJUY1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monetary Value"
      ],
      "metadata": {
        "id": "0EkMa0NBb0O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column 'total' to store transaction amounts for each purchase\n",
        "df['total'] = df['transaction_amount']\n",
        "\n",
        "# Group data by customer_id and sum the total transaction amounts per customer\n",
        "monetary_df = df.groupby(by='customer_id', as_index=False)['total'].sum()\n",
        "\n",
        "# Rename the columns to lowercase and meaningful names\n",
        "monetary_df.columns = ['customer_id', 'monetary']\n",
        "\n",
        "# Display the first few rows\n",
        "monetary_df.head()\n"
      ],
      "metadata": {
        "id": "DwWZtqq3ZpPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(monetary_df['monetary'], bins=30, kde=True, color='green')\n",
        "plt.title('Distribution of Total Customer Spend')\n",
        "plt.xlabel('Monetary Value (Total Spend)')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CgEuP2NscVVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RFM Score"
      ],
      "metadata": {
        "id": "iaCP8OIzgGUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge recency and frequency dataframes on customer_id to combine their metrics\n",
        "rf_df = df_recency.merge(frequency_df, on='customer_id')\n",
        "\n",
        "# Merge the above result with monetary dataframe and drop the redundant last_purchase_date column\n",
        "rfm_df = rf_df.merge(monetary_df, on='customer_id').drop(columns='last_purchase_date')\n",
        "\n",
        "# Assign ranks to customers: lower recency (more recent) ranks higher (descending),\n",
        "# while higher frequency and monetary values rank higher (ascending)\n",
        "rfm_df['R_rank'] = rfm_df['recency'].rank(ascending=False)\n",
        "rfm_df['F_rank'] = rfm_df['frequency'].rank(ascending=True)\n",
        "rfm_df['M_rank'] = rfm_df['monetary'].rank(ascending=True)\n",
        "\n",
        "# Normalize ranks to a 0-100 scale for comparability across the metrics\n",
        "rfm_df['R_rank_norm'] = (rfm_df['R_rank'] / rfm_df['R_rank'].max()) * 100\n",
        "rfm_df['F_rank_norm'] = (rfm_df['F_rank'] / rfm_df['F_rank'].max()) * 100\n",
        "rfm_df['M_rank_norm'] = (rfm_df['M_rank'] / rfm_df['M_rank'].max()) * 100\n",
        "\n",
        "# After normalization, drop the intermediate rank columns as they are no longer needed\n",
        "rfm_df.drop(columns=['R_rank', 'F_rank', 'M_rank'], inplace=True)\n",
        "\n",
        "# Show the first few rows of the final dataframe\n",
        "rfm_df.head()\n"
      ],
      "metadata": {
        "id": "auBMvpgKgFBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weights for each RFM component based on business priorities\n",
        "weight_recency = 0.15\n",
        "weight_frequency = 0.3\n",
        "weight_monetary = 0.55\n",
        "\n",
        "# Calculate the composite RFM score as a weighted sum of normalized ranks\n",
        "rfm_df['RFM_Score'] = \\\n",
        "    weight_recency * rfm_df['R_rank_norm'] + \\\n",
        "    weight_frequency * rfm_df['F_rank_norm'] + \\\n",
        "    weight_monetary * rfm_df['M_rank_norm']\n",
        "\n",
        "# Scale down the RFM score for easier interpretation or alignment with business KPIs\n",
        "rfm_df['RFM_Score'] *= 0.05\n",
        "rfm_df = rfm_df.round(2)\n",
        "\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "buLc_nvwjx1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(rfm_df['RFM_Score'], bins=20, kde=True, color='purple')\n",
        "plt.title('Distribution of Composite RFM Scores')\n",
        "plt.xlabel('RFM Score')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Li3WquJnluGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment Customers"
      ],
      "metadata": {
        "id": "y1qCxbOZnF1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define thresholds at 20th, 50th, and 80th percentiles of the RFM score\n",
        "percentiles = np.percentile(rfm_df['RFM_Score'], [20, 50, 80])\n",
        "\n",
        "# Apply conditions based on percentile thresholds\n",
        "rfm_df['Customer_Segment'] = np.where(rfm_df['RFM_Score'] >= percentiles[2], 'Top Customers',\n",
        "                             np.where(rfm_df['RFM_Score'] >= percentiles[1], 'High Value Customers',\n",
        "                             np.where(rfm_df['RFM_Score'] >= percentiles[0], 'Medium Value Customers', 'Low Value Customers')))\n",
        "\n",
        "# Display segment distribution\n",
        "print(rfm_df['Customer_Segment'].value_counts())\n"
      ],
      "metadata": {
        "id": "a0L3-vhdnHfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the occurrences of each segment\n",
        "segment_counts = rfm_df['Customer_Segment'].value_counts()\n",
        "\n",
        "# Create a pie chart\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.pie(segment_counts, labels=segment_counts.index, autopct='%1.1f%%',\n",
        "        startangle=140, colors=['gold', 'lightgreen', 'lightskyblue', 'lightcoral'],\n",
        "        labeldistance=1.03)\n",
        "plt.title(\"Customer Segment Distribution by RFM Score Percentiles\")\n",
        "plt.axis('equal')  # Equal aspect ratio ensures the pie chart is circular\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rRnUIDdLnVWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}